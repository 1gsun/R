{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 \n",
    "## Wenjie Sun (WS854)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘memoise’, ‘whisker’, ‘rstudioapi’, ‘git2r’, ‘withr’\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Downloading GitHub repo IRkernel/IRkernel@master\n",
      "from URL https://api.github.com/repos/IRkernel/IRkernel/zipball/master\n",
      "Warning message:\n",
      "“GitHub repo contains submodules, may not function as expected!”Installing IRkernel\n",
      "Warning message in utils::untar(src, exdir = target, compressed = \"gzip\"):\n",
      "“‘/usr/bin/gnutar -xf '/var/folders/0_/_ztstqr576q_6bg61mmgp14m0000gn/T//Rtmpj3AUP5/digest_0.6.12.tar.gz' -C '/var/folders/0_/_ztstqr576q_6bg61mmgp14m0000gn/T//Rtmpj3AUP5/devtoolse1f03758302f'’ returned error code 127”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in system(cmd, intern = TRUE): error in running command\n",
     "output_type": "error",
     "traceback": [
      "Error in system(cmd, intern = TRUE): error in running command\nTraceback:\n",
      "1. devtools::install_github(\"IRkernel/IRkernel\")",
      "2. install_remotes(remotes, quiet = quiet, ...)",
      "3. vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))",
      "4. FUN(X[[i]], ...)",
      "5. install(source, ..., quiet = quiet, metadata = metadata)",
      "6. install_deps(pkg, dependencies = initial_deps, upgrade = upgrade_dependencies, \n .     threads = threads, force_deps = force_deps, quiet = quiet, \n .     ...)",
      "7. update(pkg, ..., Ncpus = threads, quiet = quiet, upgrade = upgrade)",
      "8. update.package_deps(pkg, ..., Ncpus = threads, quiet = quiet, \n .     upgrade = upgrade)",
      "9. install_remotes(object$remote[behind], ..., quiet = quiet)",
      "10. vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))",
      "11. FUN(X[[i]], ...)",
      "12. source_pkg(bundle, subdir = remote$subdir)",
      "13. source_pkg_info(path = path, subdir = subdir)",
      "14. decompress(path, outdir)",
      "15. getrootdir(utils::untar(src, compressed = \"gzip\", list = TRUE))",
      "16. nchar(gsub(\"[^/]\", \"\", file_list))",
      "17. gsub(\"[^/]\", \"\", file_list)",
      "18. utils::untar(src, compressed = \"gzip\", list = TRUE)",
      "19. system(cmd, intern = TRUE)"
     ]
    }
   ],
   "source": [
    "install.packages('devtools')\n",
    "devtools::install_github('IRkernel/IRkernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘XML’\n",
      "\n",
      "Warning message in install.packages(\"quanteda\"):\n",
      "“installation of package ‘XML’ had non-zero exit status”Warning message in install.packages(\"quanteda\"):\n",
      "“installation of package ‘quanteda’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"quanteda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(quanteda)\n",
    "Q1_lepen <- c(lepen1= \"immigration women assimilate afraid win\",\n",
    "        lepen2 = \"culture voter economy president help\",\n",
    "        lepen3 = \"economy voter immigration president culture\")\n",
    "Q1_macron <- c(\n",
    "        macron1 = \"voter women help reform education\",\n",
    "        macron2 = \"union economy hope immigration neighbourhood\",\n",
    "        marcon3 = \"win union europe elect president\",\n",
    "        macro4 = \"success german culture help french\")\n",
    "Q1_new <- c(new = \"immigration voter culture help neighbourhood\")\n",
    "lepen_dfm <- dfm(Q1_lepen)\n",
    "macron_dfm <- dfm(Q1_macron)\n",
    "new_dfm <- dfm(Q1_new)\n",
    "lepensum <- sum(lepen_dfm)\n",
    "macrosum <- sum(macron_dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "20"
      ],
      "text/latex": [
       "20"
      ],
      "text/markdown": [
       "20"
      ],
      "text/plain": [
       "[1] 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "macrosum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.25e-07"
      ],
      "text/latex": [
       "6.25e-07"
      ],
      "text/markdown": [
       "6.25e-07"
      ],
      "text/plain": [
       "[1] 6.25e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# without smoothing \n",
    "newwords <- colnames(new_dfm)\n",
    "macron_p <- 1 \n",
    "lepen_p <-1\n",
    "\n",
    "# try count number of occurance of a praticualr word from the next text \n",
    "# and find the probability of each from both classes then update the total probabily \n",
    "for (i in (1:length(newwords))) {\n",
    "    macron_count <- try(sum(macron_dfm[,newwords[i]]))\n",
    "    if (class(macron_count) == \"try-error\" ) {\n",
    "        macron_count <- 0 \n",
    "    }\n",
    "    macron_p <- macron_p * (macron_count/macrosum)\n",
    "    \n",
    "    lepen_count <- try(sum(lepen_dfm[,newwords[i]]))\n",
    "    if (class(lepen_count) == \"try-error\" ) {\n",
    "        lepen_count <- 0 \n",
    "    }\n",
    "    lepen_p <- lepen_p * (lepen_count/lepensum)\n",
    "}\n",
    "\n",
    "macron_p\n",
    "lepen_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Macron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted textmodel of type: Naive Bayes\n",
       "\n",
       "    lp(lepen) lp(macron)    Pr(lepen) Pr(macron) Predicted\n",
       "new      -Inf  -14.97866       0.0000     1.0000    macron\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use package \n",
    "Q1_training <- c(lepen1= \"immigration women assimilate afraid win\",\n",
    "        lepen2 = \"culture voter economy president help\",\n",
    "        macron1 = \"voter women help reform education\",\n",
    "        macron2 = \"union economy hope immigration neighbourhood\",\n",
    "        marcon3 = \"win union europe elect president\",\n",
    "        lepen3 = \"economy voter immigration president culture\",\n",
    "        macro4 = \"success german culture help french\",\n",
    "        new = \"immigration voter culture help neighbourhood\")\n",
    "Q1_dfm <- dfm(Q1_training) # since neighborhood and neighbourhood spelit differently\n",
    "training_class<-factor(c(\"lepen\",\"lepen\",\"macron\",\"macron\",\"macron\",\"lepen\",\"macron\"),ordered = TRUE)\n",
    "\n",
    "# Predict without smoothing\n",
    "predict(textmodel_NB(Q1_dfm[1:7],training_class,smooth = 0),newdata = Q1_dfm[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Becasue \"neighbourhood\" doesn't exist in any of lepen's speech, thus the probabily on this word given by lepen becomes 0. And when mutply  all the probability, the total probabiltly becomes 0 too. However, I would not trust the finding becasue the prediction should not be based on one signle word. Also, the probability of Macron is also really small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.675947072908379"
      ],
      "text/latex": [
       "0.675947072908379"
      ],
      "text/markdown": [
       "0.675947072908379"
      ],
      "text/plain": [
       "[1] 0.6759471"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with smoothing \n",
    "newwords <- colnames(new_dfm)\n",
    "macron_p <- 1 \n",
    "lepen_p <-1\n",
    "\n",
    "# try count number of occurance of a praticualr word from the next text \n",
    "# and find the probability of each from both classes then update the total probabily \n",
    "# on demoniator, add number of words used in each class\n",
    "for (i in (1:length(newwords))) {\n",
    "    macron_count <- try(sum(macron_dfm[,newwords[i]]))\n",
    "    if (class(macron_count) == \"try-error\" ) {\n",
    "        macron_count <- 0 \n",
    "    }\n",
    "    macron_p <- macron_p * ((macron_count+1)/(macrosum+length(colnames(macron_dfm))))\n",
    "    \n",
    "    lepen_count <- try(sum(lepen_dfm[,newwords[i]]))\n",
    "    if (class(lepen_count) == \"try-error\" ) {\n",
    "        lepen_count <- 0 \n",
    "    }\n",
    "    lepen_p <- lepen_p * ((lepen_count+1)/(lepensum+length(colnames(lepen_dfm))))\n",
    "}\n",
    "\n",
    "(3*lepen_p) / (4*(lepen_p+ macron_p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Lepen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted textmodel of type: Naive Bayes\n",
       "\n",
       "    lp(lepen) lp(macron)    Pr(lepen) Pr(macron) Predicted\n",
       "new  -14.4809  -15.26634       0.6869     0.3131     lepen\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict with smoothing with existing package \n",
    "predict(textmodel_NB(Q1_dfm[1:7],training_class,smooth = 1),newdata = Q1_dfm[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After smoothing, the prediction is now for lepen. This makes more sense since other owrds like \"immgration\" or \"culture\" are frequently used by him. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No need for any pre-processing for 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Text</th><th scope=col>Score</th><th scope=col>Y</th><th scope=col>Anchor_Pos</th><th scope=col>Anchor_Neg</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 5249                                                                                                                                                                                                                                                                                         </td><td>My grandchildren have watched this and ICarly and I reluctantly watched as well.  I found that both programs were entertaining and fresh.  Victorious adds the musical element to supplement the light hearted humor.  Definitely not bound for an Emmy but still the silliness is infectious.</td><td>4                                                                                                                                                                                                                                                                                             </td><td>1                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td></tr>\n",
       "\t<tr><td> 8679                                                                                                                                                                                                                                                                                         </td><td>I am no longer interested in watching TV dramas that victimize women and children.  If this is the only story the producers have to tell, I'm not going to give it a good rating.                                                                                                             </td><td>1                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td><td>1                                                                                                                                                                                                                                                                                             </td></tr>\n",
       "\t<tr><td>27027                                                                                                                                                                                                                                                                                         </td><td>I could not even get through the first 15 minutes of the first episode.  Would you hang out sober in a bar for yuks? Ask any bar tender...                                                                                                                                                    </td><td>1                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td><td>0                                                                                                                                                                                                                                                                                             </td><td>1                                                                                                                                                                                                                                                                                             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " X & Text & Score & Y & Anchor\\_Pos & Anchor\\_Neg\\\\\n",
       "\\hline\n",
       "\t  5249                                                                                                                                                                                                                                                                                          & My grandchildren have watched this and ICarly and I reluctantly watched as well.  I found that both programs were entertaining and fresh.  Victorious adds the musical element to supplement the light hearted humor.  Definitely not bound for an Emmy but still the silliness is infectious. & 4                                                                                                                                                                                                                                                                                              & 1                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                             \\\\\n",
       "\t  8679                                                                                                                                                                                                                                                                                          & I am no longer interested in watching TV dramas that victimize women and children.  If this is the only story the producers have to tell, I'm not going to give it a good rating.                                                                                                              & 1                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                              & 1                                                                                                                                                                                                                                                                                             \\\\\n",
       "\t 27027                                                                                                                                                                                                                                                                                          & I could not even get through the first 15 minutes of the first episode.  Would you hang out sober in a bar for yuks? Ask any bar tender...                                                                                                                                                     & 1                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                              & 0                                                                                                                                                                                                                                                                                              & 1                                                                                                                                                                                                                                                                                             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "X | Text | Score | Y | Anchor_Pos | Anchor_Neg | \n",
       "|---|---|---|\n",
       "|  5249                                                                                                                                                                                                                                                                                          | My grandchildren have watched this and ICarly and I reluctantly watched as well.  I found that both programs were entertaining and fresh.  Victorious adds the musical element to supplement the light hearted humor.  Definitely not bound for an Emmy but still the silliness is infectious. | 4                                                                                                                                                                                                                                                                                              | 1                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | \n",
       "|  8679                                                                                                                                                                                                                                                                                          | I am no longer interested in watching TV dramas that victimize women and children.  If this is the only story the producers have to tell, I'm not going to give it a good rating.                                                                                                              | 1                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | 1                                                                                                                                                                                                                                                                                              | \n",
       "| 27027                                                                                                                                                                                                                                                                                          | I could not even get through the first 15 minutes of the first episode.  Would you hang out sober in a bar for yuks? Ask any bar tender...                                                                                                                                                     | 1                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | 0                                                                                                                                                                                                                                                                                              | 1                                                                                                                                                                                                                                                                                              | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  X    \n",
       "1  5249\n",
       "2  8679\n",
       "3 27027\n",
       "  Text                                                                                                                                                                                                                                                                                          \n",
       "1 My grandchildren have watched this and ICarly and I reluctantly watched as well.  I found that both programs were entertaining and fresh.  Victorious adds the musical element to supplement the light hearted humor.  Definitely not bound for an Emmy but still the silliness is infectious.\n",
       "2 I am no longer interested in watching TV dramas that victimize women and children.  If this is the only story the producers have to tell, I'm not going to give it a good rating.                                                                                                             \n",
       "3 I could not even get through the first 15 minutes of the first episode.  Would you hang out sober in a bar for yuks? Ask any bar tender...                                                                                                                                                    \n",
       "  Score Y Anchor_Pos Anchor_Neg\n",
       "1 4     1 0          0         \n",
       "2 1     0 0          1         \n",
       "3 1     0 0          1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "df.reviews<- read.csv(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/amazon_reviews.csv\",stringsAsFactors = F)\n",
    "# recode the label 1/0  \n",
    "df.reviews$Y <- ifelse(df.reviews$Score >mean(df.reviews$Score), 1, 0)\n",
    "# code anchor positive \n",
    "df.reviews$Anchor_Pos<-ifelse(df.reviews$Score ==5 , 1, 0)\n",
    "# code anchor negative\n",
    "df.reviews$Anchor_Neg<-ifelse(df.reviews$Score ==1 , 1, 0)\n",
    "# preview the head\n",
    "head(df.reviews,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### since the negative and positve list doesn't look like is stemed, I will process the data without stemming. However, all the words in both neg/pos dictionary are lowercase and has no stopwords, so I will lower case and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'zapped'</li>\n",
       "\t<li>'zaps'</li>\n",
       "\t<li>'zealot'</li>\n",
       "\t<li>'zealous'</li>\n",
       "\t<li>'zealously'</li>\n",
       "\t<li>'zombie'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'zapped'\n",
       "\\item 'zaps'\n",
       "\\item 'zealot'\n",
       "\\item 'zealous'\n",
       "\\item 'zealously'\n",
       "\\item 'zombie'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'zapped'\n",
       "2. 'zaps'\n",
       "3. 'zealot'\n",
       "4. 'zealous'\n",
       "5. 'zealously'\n",
       "6. 'zombie'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"zapped\"    \"zaps\"      \"zealot\"    \"zealous\"   \"zealously\" \"zombie\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(readLines(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/negative-words.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a negative dictionary\n",
    "negdict <- dictionary(list(neg=readLines(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/negative-words.txt\")))\n",
    "# create a dfm of negative words only\n",
    "dfm_neg<-dfm(df.reviews$Text, dictionary=negdict,tolower = TRUE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE)\n",
    "# create a positive dictionary\n",
    "posdict <- dictionary(list(pos=readLines(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/positive-words.txt\")))\n",
    "# create a dfm of positive words only\n",
    "dfm_pos<-dfm(df.reviews$Text, dictionary=posdict,tolower = TRUE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_score <- matrix(0,ncol=1,nrow=10000)\n",
    "\n",
    "# calculate dichotomous vector by number of positive words minus number of negative words\n",
    "for (i in (1:nrow(sentiment_score))) {\n",
    "  sentiment_score[i]<-dfm_pos[i]-dfm_neg[i]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | \n",
       "| 1 | \n",
       "| 1 | \n",
       "| 1 | \n",
       "| 1 | \n",
       "| 1 | \n",
       "| 0 | \n",
       "| 0 | \n",
       "| 1 | \n",
       "| 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]\n",
       " [1,] 1   \n",
       " [2,] 1   \n",
       " [3,] 1   \n",
       " [4,] 1   \n",
       " [5,] 1   \n",
       " [6,] 1   \n",
       " [7,] 0   \n",
       " [8,] 0   \n",
       " [9,] 1   \n",
       "[10,] 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make it a binary vector (1 - 0 )\n",
    "\n",
    "dichotomous_vector <- ifelse(sentiment_score<0,0,1)\n",
    "head(dichotomous_vector,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDWlDQ1BJQ0MgUHJvZmlsZQAA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\ngg==",
      "text/plain": [
       "Plot with title “Histogram of sentiment_score”"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hist(sentiment_score,breaks=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8452"
      ],
      "text/latex": [
       "0.8452"
      ],
      "text/markdown": [
       "0.8452"
      ],
      "text/plain": [
       "[1] 0.8452"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(dichotomous_vector)/nrow(dichotomous_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 84.52 % of reviews have a postive score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  \n",
       "dichotomous_vector    0    1\n",
       "                 0 1291  257\n",
       "                 1 3716 4736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#create confusion matrix\n",
    "tab<- table(dichotomous_vector,df.reviews$Y)\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.6027"
      ],
      "text/latex": [
       "0.6027"
      ],
      "text/markdown": [
       "0.6027"
      ],
      "text/plain": [
       "[1] 0.6027"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy <- (tab[1,1]+tab[2,2])/sum(tab)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.560340747752011"
      ],
      "text/latex": [
       "0.560340747752011"
      ],
      "text/markdown": [
       "0.560340747752011"
      ],
      "text/plain": [
       "[1] 0.5603407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision <- tab[2,2] /(tab[2,2]+tab[2,1])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.948527939114761"
      ],
      "text/latex": [
       "0.948527939114761"
      ],
      "text/markdown": [
       "0.948527939114761"
      ],
      "text/plain": [
       "[1] 0.9485279"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall <- tab[2,2] /(tab[2,2]+tab[1,2])\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Add Sentiment Score into DF\n",
    "df.reviews$Sentiment <- sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a df to rank sentiment score\n",
    "df_SentRank<- df.reviews[,c(\"X\",\"Sentiment\")]\n",
    "df_SentRank<- df_SentRank[order(-df_SentRank[,2]), ]\n",
    "df_SentRank$Rank <- seq(1, 10000, by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a df to rank actual score\n",
    "df_ActRank<- df.reviews[,c(\"X\",\"Score\")]\n",
    "df_ActRank<- df_ActRank[order(-df_ActRank[,2]), ]\n",
    "df_ActRank$Rank <- seq(1, 10000, by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "27389662"
      ],
      "text/latex": [
       "27389662"
      ],
      "text/markdown": [
       "27389662"
      ],
      "text/plain": [
       "[1] 27389662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RankSum = 0\n",
    "# loop through Actual rank to find the coropsonding sentiment rank by the key X \n",
    "for (i in (1:nrow(df_ActRank))) {\n",
    "  RankSum = RankSum + abs (df_SentRank[which(df_SentRank$X ==df_ActRank$X[i] ),]$Rank - df_ActRank[which(df_ActRank$X ==df_ActRank$X[i] ),]$Rank)   \n",
    "}\n",
    "RankSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] - uniform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df.reviews is the original dataset (the only change is it is now appended a sentiment score from previous question)\n",
    "\n",
    "# shuffle data (since it is a supervised test, I will rather shuffle data first)\n",
    "df1 <- df.reviews[sample(nrow(df.reviews)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I chose to stem the words for this task. For example, running and run, I think it is very close to each other and I want them to represent the same probabiliy in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in dfm(df1$Text, tolower = FALSE, stem = FALSE, remove = stopwords(\"english\"), : object 'df1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in dfm(df1$Text, tolower = FALSE, stem = FALSE, remove = stopwords(\"english\"), : object 'df1' not found\nTraceback:\n",
      "1. dfm(df1$Text, tolower = FALSE, stem = FALSE, remove = stopwords(\"english\"), \n .     removePunct = TRUE)"
     ]
    }
   ],
   "source": [
    "# generate dfm of all text \n",
    "dfm_df <- dfm(df1$Text,tolower = FALSE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE)\n",
    "# training class\n",
    "training_class <-factor(df1$Y[1:2000],ordered = TRUE)\n",
    "# predict function \n",
    "pred<- predict(textmodel_NB(dfm_df[1:2000],training_class,smooth = 1, prior = \"uniform\"),newdata =dfm_df[2001:10000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "       0    1\n",
       "  0 3338 1296\n",
       "  1  677 2689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab<- table(pred$nb.predicted,df1$Y[2001:10000])\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.753375"
      ],
      "text/latex": [
       "0.753375"
      ],
      "text/markdown": [
       "0.753375"
      ],
      "text/plain": [
       "[1] 0.753375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy <- (tab[1,1]+tab[2,2])/sum(tab)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.798871063576946"
      ],
      "text/latex": [
       "0.798871063576946"
      ],
      "text/markdown": [
       "0.798871063576946"
      ],
      "text/plain": [
       "[1] 0.7988711"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision <- tab[2,2] /(tab[2,2]+tab[2,1])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.674780426599749"
      ],
      "text/latex": [
       "0.674780426599749"
      ],
      "text/markdown": [
       "0.674780426599749"
      ],
      "text/plain": [
       "[1] 0.6747804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall <- tab[2,2] /(tab[2,2]+tab[1,2])\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] - docfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# predict function \n",
    "pred<- predict(textmodel_NB(dfm_df[1:2000],training_class,smooth = 1, prior = \"docfreq\"),newdata =dfm_df[2001:10000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "       0    1\n",
       "  0 3333 1289\n",
       "  1  682 2696"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab<- table(pred$nb.predicted,df1$Y[2001:10000])\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.753625"
      ],
      "text/latex": [
       "0.753625"
      ],
      "text/markdown": [
       "0.753625"
      ],
      "text/plain": [
       "[1] 0.753625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy <- (tab[1,1]+tab[2,2])/sum(tab)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.798105387803434"
      ],
      "text/latex": [
       "0.798105387803434"
      ],
      "text/markdown": [
       "0.798105387803434"
      ],
      "text/plain": [
       "[1] 0.7981054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision <- tab[2,2] /(tab[2,2]+tab[2,1])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.676537013801757"
      ],
      "text/latex": [
       "0.676537013801757"
      ],
      "text/markdown": [
       "0.676537013801757"
      ],
      "text/plain": [
       "[1] 0.676537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall <- tab[2,2] /(tab[2,2]+tab[1,2])\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will assume docfreq may have a slightly higher accuracy, but not guarantted. The reason is i don't know if all these reviews were for the same or similar product. If these reviews are randomly for any product on amazon, i think using docfreq as prior wouldn't help to make it more accuracy (since the chance of having a word appeared in any review now becomes almost random). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### [3]\n",
    "#### It is the same as question 1, without smoothing, new word that doesn't exist in the training set will be counted as 0 probabiliy. So, the overall probability will be 0 for that review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataframe only has anchor positive / negative \n",
    "anchor_pos <- df.reviews[which(df.reviews$Anchor_Pos==1), ]\n",
    "anchor_neg <- df.reviews[which(df.reviews$Anchor_Neg==1), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same process as 2(c). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate dfm in matrix \n",
    "anchor_pos_dfm <- as.matrix(dfm(anchor_pos$Text,tolower = TRUE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE))\n",
    "anchor_neg_dfm <- as.matrix(dfm(anchor_neg$Text,tolower = TRUE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a list of all the words in anchor positive and negative reviews,\n",
    "# which is a list of all the words to get all wordscore \n",
    "all_words <- unique(c(colnames(anchor_pos_dfm),colnames(anchor_neg_dfm)))\n",
    "\n",
    "# total number of words in positive reviews and negative reviews \n",
    "total_pos <- sum(anchor_pos_dfm )\n",
    "total_neg <- sum(anchor_neg_dfm )\n",
    "\n",
    "# create a matrix for all the postive and negative probability \n",
    "prob <- matrix (0,ncol = 2, nrow = length(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use a for loop to search if a praticular word exists in the positive document, \n",
    "# if yes, then calculate the (total number of apperance / total word number in positive)\n",
    "# else, it is 0 \n",
    "for (i in (1:length(all_words))) {\n",
    "    pos_count <- try(sum(anchor_pos_dfm[,all_words[i]]))\n",
    "    if (class(pos_count) == \"try-error\" ) {\n",
    "        pos_count <- 0 \n",
    "    }\n",
    "    prob[i,1] <- pos_count/total_pos    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same logic for negative words\n",
    "for (i in (1:length(all_words))) {\n",
    "    neg_count <- try(sum(anchor_neg_dfm[,all_words[i]]))\n",
    "    if (class(neg_count) == \"try-error\" ) {\n",
    "        neg_count <- 0 \n",
    "    }\n",
    "    prob[i,2] <- neg_count/total_neg    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "df_prob<- as.data.frame(prob, row.names = all_words)\n",
    "colnames(df_prob) <- c(\"pos_prob\", \"neg_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate positive and negative probabiliy \n",
    "df_prob$P_i_Pos <- with(df_prob,(pos_prob/(pos_prob+neg_prob)))\n",
    "df_prob$P_i_Neg <- with(df_prob,(neg_prob/(pos_prob+neg_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the wordscore\n",
    "df_prob$wordscore <- with(df_prob,(P_i_Pos-P_i_Neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "9439"
      ],
      "text/latex": [
       "9439"
      ],
      "text/markdown": [
       "9439"
      ],
      "text/plain": [
       "[1] 9439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# total number of pure positive word\n",
    "extrem_pos <- df_prob[which(df_prob$wordscore == 1),]\n",
    "length(extrem_pos$wordscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "7250"
      ],
      "text/latex": [
       "7250"
      ],
      "text/markdown": [
       "7250"
      ],
      "text/plain": [
       "[1] 7250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# total number of pure negative word\n",
    "extrem_neg <- df_prob[which(df_prob$wordscore == -1),]\n",
    "length(extrem_neg$wordscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pos_prob</th><th scope=col>neg_prob</th><th scope=col>P_i_Pos</th><th scope=col>P_i_Neg</th><th scope=col>wordscore</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>poirot</th><td>0.0003155229</td><td>0           </td><td>1           </td><td>0           </td><td>1           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & pos\\_prob & neg\\_prob & P\\_i\\_Pos & P\\_i\\_Neg & wordscore\\\\\n",
       "\\hline\n",
       "\tpoirot & 0.0003155229 & 0            & 1            & 0            & 1           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | pos_prob | neg_prob | P_i_Pos | P_i_Neg | wordscore | \n",
       "|---|\n",
       "| poirot | 0.0003155229 | 0            | 1            | 0            | 1            | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       pos_prob     neg_prob P_i_Pos P_i_Neg wordscore\n",
       "poirot 0.0003155229 0        1       0       1        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most extrem postive word \n",
    "extrem_pos[which(extrem_pos$pos_prob == max(extrem_pos$pos_prob)),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pos_prob</th><th scope=col>neg_prob</th><th scope=col>P_i_Pos</th><th scope=col>P_i_Neg</th><th scope=col>wordscore</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>zero</th><td>0          </td><td>0.000373781</td><td>0          </td><td>1          </td><td>-1         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & pos\\_prob & neg\\_prob & P\\_i\\_Pos & P\\_i\\_Neg & wordscore\\\\\n",
       "\\hline\n",
       "\tzero & 0           & 0.000373781 & 0           & 1           & -1         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | pos_prob | neg_prob | P_i_Pos | P_i_Neg | wordscore | \n",
       "|---|\n",
       "| zero | 0           | 0.000373781 | 0           | 1           | -1          | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     pos_prob neg_prob    P_i_Pos P_i_Neg wordscore\n",
       "zero 0        0.000373781 0       1       -1       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most extrem negative word\n",
    "extrem_neg[which(extrem_neg$neg_prob == max(extrem_neg$neg_prob)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# reload the whole data\n",
    "reviews_dfm <- as.matrix(dfm(df.reviews$Text,tolower = TRUE, stem = FALSE, remove = stopwords(\"english\"),removePunct = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove all the words that don't exist in the wordscore matrix \n",
    "reviews_dfm <- reviews_dfm[ ,which((colnames(reviews_dfm) %in% rownames(df_prob))==TRUE)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a vector to store wordscore result \n",
    "wordscore_review <- matrix (0,ncol = 1, nrow = nrow(reviews_dfm))\n",
    "# create a list of reviews_dfm colnames (which are all the words that have wordscore)\n",
    "reviews_dfm_colname<-colnames(reviews_dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for every text in the reviews_dfm\n",
    "# for every word in each text\n",
    "# calculate the number of times / total number of words in that text * wordscore of that word \n",
    "\n",
    "for (i in (1:nrow(reviews_dfm))){\n",
    "    prob <- 0 \n",
    "    numberwords <- sum(reviews_dfm[i,])\n",
    "    for (j in (1:length(reviews_dfm_colname))){        \n",
    "        if (reviews_dfm[i,j]==0){\n",
    "            prob <- prob+0 \n",
    "\n",
    "        }\n",
    "        else {\n",
    "            word_score<- df_prob[which(rownames(df_prob)==reviews_dfm_colname[j]),]$wordscore\n",
    "            prob <- prob + (reviews_dfm[i,j]/numberwords)*word_score   \n",
    "\n",
    "        }            \n",
    "        \n",
    "    }\n",
    "    wordscore_review[i] <- prob   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reviews$wordscore <- wordscore_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_SentRank1 <- df.reviews[,c(\"X\",\"wordscore\")]\n",
    "df_SentRank1 <- df_SentRank1[order(-df_SentRank1[,2]),]\n",
    "df_SentRank1$Rank <- seq(1,10000,by =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "14371636"
      ],
      "text/latex": [
       "14371636"
      ],
      "text/markdown": [
       "14371636"
      ],
      "text/plain": [
       "[1] 14371636"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RankSum1 = 0\n",
    "\n",
    "for (i in (1:nrow(df_ActRank))) {\n",
    "  RankSum1 = RankSum1 + abs (df_SentRank1[which(df_SentRank1$X ==df_ActRank$X[i] ),]$Rank - df_ActRank[which(df_ActRank$X ==df_ActRank$X[i] ),]$Rank)   \n",
    "}\n",
    "RankSum1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks that the wordscore has a better rank. However, i am not sure if this is a fair evulation because the actual score is only 1, 2, 3, 4, 5, so the rank can be 1 or 1000 for the same score, which is pretty random/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I think SVM and NB use all available data, while dictionary and wordscore only use partial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tm\")\n",
    "install.packages(\"NLP\")\n",
    "install.packages(\"https://cran.r-project.org/bin/windows/contrib/3.4/prodlim_1.6.1.zip\",repos = NULL, method = \"libcurl\")\n",
    "install.packages(\"RTextTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(NLP)\n",
    "library(tm)\n",
    "library(RTextTools)\n",
    "library(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#reload data \n",
    "df.reviews<- read.csv(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/amazon_reviews.csv\",stringsAsFactors = F)\n",
    "# recode the label 1/0  \n",
    "df.reviews$Y <- ifelse(df.reviews$Score >mean(df.reviews$Score), 1, 0)\n",
    "# code anchor positive \n",
    "df.reviews$Anchor_Pos<-ifelse(df.reviews$Score ==5 , 1, 0)\n",
    "# code anchor negative\n",
    "df.reviews$Anchor_Neg<-ifelse(df.reviews$Score ==1 , 1, 0)\n",
    "df.reviews<- df.reviews[1:1000,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same as previous question, stem word and and remove puncutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtm  <- create_matrix(df.reviews$Text, language=\"english\", stemWords = TRUE,\n",
    "                      weighting = weightTfIdf, removePunctuation = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "container <- create_container(dtm, t(df.reviews$Y), trainSize=1:length(df.reviews$Y),\n",
    "                              virgin=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Out of Sample Accuracy = 0.9800995\n",
      "Fold 2 Out of Sample Accuracy = 0.96\n",
      "Fold 3 Out of Sample Accuracy = 0.9624413\n",
      "Fold 4 Out of Sample Accuracy = 0.974026\n",
      "Fold 5 Out of Sample Accuracy = 0.9689922\n"
     ]
    }
   ],
   "source": [
    "cv.svm <- cross_validate(container, nfold=5, algorithm = 'SVM', kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_size <- seq(0.1, 0.9, by = 0.1)\n",
    "SVM_accuracy <- matrix (0,ncol = 1, nrow = length(train_test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Out of Sample Accuracy = 0.8058252\n",
      "Fold 2 Out of Sample Accuracy = 0.8172589\n",
      "Fold 3 Out of Sample Accuracy = 0.8121547\n",
      "Fold 4 Out of Sample Accuracy = 0.8599034\n",
      "Fold 5 Out of Sample Accuracy = 0.8190476\n",
      "Fold 1 Out of Sample Accuracy = 0.8029557\n",
      "Fold 2 Out of Sample Accuracy = 0.8578947\n",
      "Fold 3 Out of Sample Accuracy = 0.8028169\n",
      "Fold 4 Out of Sample Accuracy = 0.8481675\n",
      "Fold 5 Out of Sample Accuracy = 0.8872549\n",
      "Fold 1 Out of Sample Accuracy = 0.8243902\n",
      "Fold 2 Out of Sample Accuracy = 0.8121827\n",
      "Fold 3 Out of Sample Accuracy = 0.8229665\n",
      "Fold 4 Out of Sample Accuracy = 0.8274112\n",
      "Fold 5 Out of Sample Accuracy = 0.8497409\n",
      "Fold 1 Out of Sample Accuracy = 0.7673267\n",
      "Fold 2 Out of Sample Accuracy = 0.8396226\n",
      "Fold 3 Out of Sample Accuracy = 0.8638743\n",
      "Fold 4 Out of Sample Accuracy = 0.8248848\n",
      "Fold 5 Out of Sample Accuracy = 0.8212291\n",
      "Fold 1 Out of Sample Accuracy = 0.8311111\n",
      "Fold 2 Out of Sample Accuracy = 0.8502674\n",
      "Fold 3 Out of Sample Accuracy = 0.8461538\n",
      "Fold 4 Out of Sample Accuracy = 0.8297872\n",
      "Fold 5 Out of Sample Accuracy = 0.8445596\n",
      "Fold 1 Out of Sample Accuracy = 0.8599034\n",
      "Fold 2 Out of Sample Accuracy = 0.8010753\n",
      "Fold 3 Out of Sample Accuracy = 0.8302752\n",
      "Fold 4 Out of Sample Accuracy = 0.8341463\n",
      "Fold 5 Out of Sample Accuracy = 0.8378378\n",
      "Fold 1 Out of Sample Accuracy = 0.8031088\n",
      "Fold 2 Out of Sample Accuracy = 0.7947368\n",
      "Fold 3 Out of Sample Accuracy = 0.8380952\n",
      "Fold 4 Out of Sample Accuracy = 0.8571429\n",
      "Fold 5 Out of Sample Accuracy = 0.8490566\n",
      "Fold 1 Out of Sample Accuracy = 0.8599034\n",
      "Fold 2 Out of Sample Accuracy = 0.8210526\n",
      "Fold 3 Out of Sample Accuracy = 0.7904762\n",
      "Fold 4 Out of Sample Accuracy = 0.8181818\n",
      "Fold 5 Out of Sample Accuracy = 0.8571429\n",
      "Fold 1 Out of Sample Accuracy = 0.7873563\n",
      "Fold 2 Out of Sample Accuracy = 0.8172589\n",
      "Fold 3 Out of Sample Accuracy = 0.8465347\n",
      "Fold 4 Out of Sample Accuracy = 0.8207547\n",
      "Fold 5 Out of Sample Accuracy = 0.8611111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.8228380</td></tr>\n",
       "\t<tr><td>0.8398179</td></tr>\n",
       "\t<tr><td>0.8273383</td></tr>\n",
       "\t<tr><td>0.8233875</td></tr>\n",
       "\t<tr><td>0.8403758</td></tr>\n",
       "\t<tr><td>0.8326476</td></tr>\n",
       "\t<tr><td>0.8284281</td></tr>\n",
       "\t<tr><td>0.8293514</td></tr>\n",
       "\t<tr><td>0.8266031</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.8228380\\\\\n",
       "\t 0.8398179\\\\\n",
       "\t 0.8273383\\\\\n",
       "\t 0.8233875\\\\\n",
       "\t 0.8403758\\\\\n",
       "\t 0.8326476\\\\\n",
       "\t 0.8284281\\\\\n",
       "\t 0.8293514\\\\\n",
       "\t 0.8266031\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.8228380 | \n",
       "| 0.8398179 | \n",
       "| 0.8273383 | \n",
       "| 0.8233875 | \n",
       "| 0.8403758 | \n",
       "| 0.8326476 | \n",
       "| 0.8284281 | \n",
       "| 0.8293514 | \n",
       "| 0.8266031 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]     \n",
       " [1,] 0.8228380\n",
       " [2,] 0.8398179\n",
       " [3,] 0.8273383\n",
       " [4,] 0.8233875\n",
       " [5,] 0.8403758\n",
       " [6,] 0.8326476\n",
       " [7,] 0.8284281\n",
       " [8,] 0.8293514\n",
       " [9,] 0.8266031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (i in (1:nrow(SVM_accuracy))) {\n",
    "    training_break <- as.integer(train_test_size[i]*nrow(df.reviews))\n",
    "    container<- create_container(dtm, t(df.reviews$Y), trainSize=1:training_break,\n",
    "                                   testSize=training_break:nrow(df.reviews), virgin=FALSE)\n",
    "    cv.svm <- cross_validate(container, nfold=5, algorithm = 'SVM', kernel = 'linear')\n",
    "    SVM_accuracy[i]<- cv.svm$meanAccuracy  \n",
    "}\n",
    "SVM_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.840375831295777"
      ],
      "text/latex": [
       "0.840375831295777"
      ],
      "text/markdown": [
       "0.840375831295777"
      ],
      "text/plain": [
       "[1] 0.8403758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(SVM_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When I used 50%, it gets max SVM accuracy. However, it seems that the ration is not that important since the accuracy is pretty close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3]\n",
    "#### I guess linear will be better since text analysis already has a large number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Out of Sample Accuracy = 0.7953488\n",
      "Fold 2 Out of Sample Accuracy = 0.785\n",
      "Fold 3 Out of Sample Accuracy = 0.8010471\n",
      "Fold 4 Out of Sample Accuracy = 0.7525773\n",
      "Fold 5 Out of Sample Accuracy = 0.7960199\n",
      "Fold 1 Out of Sample Accuracy = 0.825\n",
      "Fold 2 Out of Sample Accuracy = 0.7759563\n",
      "Fold 3 Out of Sample Accuracy = 0.7868852\n",
      "Fold 4 Out of Sample Accuracy = 0.7382199\n",
      "Fold 5 Out of Sample Accuracy = 0.7941176\n",
      "Fold 1 Out of Sample Accuracy = 0.761658\n",
      "Fold 2 Out of Sample Accuracy = 0.8252427\n",
      "Fold 3 Out of Sample Accuracy = 0.7723214\n",
      "Fold 4 Out of Sample Accuracy = 0.7574257\n",
      "Fold 5 Out of Sample Accuracy = 0.8181818\n",
      "Fold 1 Out of Sample Accuracy = 0.8232558\n",
      "Fold 2 Out of Sample Accuracy = 0.7526316\n",
      "Fold 3 Out of Sample Accuracy = 0.7703349\n",
      "Fold 4 Out of Sample Accuracy = 0.7638191\n",
      "Fold 5 Out of Sample Accuracy = 0.8191489\n",
      "Fold 1 Out of Sample Accuracy = 0.7724868\n",
      "Fold 2 Out of Sample Accuracy = 0.7945946\n",
      "Fold 3 Out of Sample Accuracy = 0.8165138\n",
      "Fold 4 Out of Sample Accuracy = 0.7810945\n",
      "Fold 5 Out of Sample Accuracy = 0.7644231\n",
      "Fold 1 Out of Sample Accuracy = 0.7511737\n",
      "Fold 2 Out of Sample Accuracy = 0.7902439\n",
      "Fold 3 Out of Sample Accuracy = 0.7529412\n",
      "Fold 4 Out of Sample Accuracy = 0.8067633\n",
      "Fold 5 Out of Sample Accuracy = 0.8252427\n",
      "Fold 1 Out of Sample Accuracy = 0.7738693\n",
      "Fold 2 Out of Sample Accuracy = 0.8074866\n",
      "Fold 3 Out of Sample Accuracy = 0.7658537\n",
      "Fold 4 Out of Sample Accuracy = 0.7927928\n",
      "Fold 5 Out of Sample Accuracy = 0.7925532\n",
      "Fold 1 Out of Sample Accuracy = 0.7837838\n",
      "Fold 2 Out of Sample Accuracy = 0.7889447\n",
      "Fold 3 Out of Sample Accuracy = 0.7512195\n",
      "Fold 4 Out of Sample Accuracy = 0.8139535\n",
      "Fold 5 Out of Sample Accuracy = 0.7918782\n",
      "Fold 1 Out of Sample Accuracy = 0.8020833\n",
      "Fold 2 Out of Sample Accuracy = 0.8010471\n",
      "Fold 3 Out of Sample Accuracy = 0.7777778\n",
      "Fold 4 Out of Sample Accuracy = 0.757732\n",
      "Fold 5 Out of Sample Accuracy = 0.7884615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.7859986</td></tr>\n",
       "\t<tr><td>0.7840358</td></tr>\n",
       "\t<tr><td>0.7869659</td></tr>\n",
       "\t<tr><td>0.7858381</td></tr>\n",
       "\t<tr><td>0.7858225</td></tr>\n",
       "\t<tr><td>0.7852730</td></tr>\n",
       "\t<tr><td>0.7865111</td></tr>\n",
       "\t<tr><td>0.7859559</td></tr>\n",
       "\t<tr><td>0.7854203</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.7859986\\\\\n",
       "\t 0.7840358\\\\\n",
       "\t 0.7869659\\\\\n",
       "\t 0.7858381\\\\\n",
       "\t 0.7858225\\\\\n",
       "\t 0.7852730\\\\\n",
       "\t 0.7865111\\\\\n",
       "\t 0.7859559\\\\\n",
       "\t 0.7854203\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.7859986 | \n",
       "| 0.7840358 | \n",
       "| 0.7869659 | \n",
       "| 0.7858381 | \n",
       "| 0.7858225 | \n",
       "| 0.7852730 | \n",
       "| 0.7865111 | \n",
       "| 0.7859559 | \n",
       "| 0.7854203 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]     \n",
       " [1,] 0.7859986\n",
       " [2,] 0.7840358\n",
       " [3,] 0.7869659\n",
       " [4,] 0.7858381\n",
       " [5,] 0.7858225\n",
       " [6,] 0.7852730\n",
       " [7,] 0.7865111\n",
       " [8,] 0.7859559\n",
       " [9,] 0.7854203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (i in (1:nrow(SVM_accuracy))) {\n",
    "    training_break <- as.integer(train_test_size[i]*nrow(df.reviews))\n",
    "    container<- create_container(dtm, t(df.reviews$Y), trainSize=1:training_break,\n",
    "                                   testSize=training_break:nrow(df.reviews), virgin=FALSE)\n",
    "    cv.svm <- cross_validate(container, nfold=5, algorithm = 'SVM', kernel = 'radial')\n",
    "    SVM_accuracy[i]<- cv.svm$meanAccuracy  \n",
    "}\n",
    "SVM_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.786965947772438"
      ],
      "text/latex": [
       "0.786965947772438"
      ],
      "text/markdown": [
       "0.786965947772438"
      ],
      "text/plain": [
       "[1] 0.7869659"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(SVM_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When i used 30%, it gets the maximum. However, it is the same as previous question that the ratio doesn't seem to be very important to impact on the accuracy. So, linear model is better than raidal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'BIH'</li>\n",
       "\t<li>'POL'</li>\n",
       "\t<li>'ESP'</li>\n",
       "\t<li>'JOR'</li>\n",
       "\t<li>'IND'</li>\n",
       "\t<li>'CAN'</li>\n",
       "\t<li>'SRB'</li>\n",
       "\t<li>'USA'</li>\n",
       "\t<li>'JPN'</li>\n",
       "\t<li>'TUR'</li>\n",
       "\t<li>'UKR'</li>\n",
       "\t<li>'GRC'</li>\n",
       "\t<li>'GBR'</li>\n",
       "\t<li>'PRT'</li>\n",
       "\t<li>'VEN'</li>\n",
       "\t<li>'PAK'</li>\n",
       "\t<li>'HKG'</li>\n",
       "\t<li>'ARG'</li>\n",
       "\t<li>'MEX'</li>\n",
       "\t<li>'MYS'</li>\n",
       "\t<li>'DEU'</li>\n",
       "\t<li>'BGD'</li>\n",
       "\t<li>'FIN'</li>\n",
       "\t<li>'ITA'</li>\n",
       "\t<li>'IDN'</li>\n",
       "\t<li>'BGR'</li>\n",
       "\t<li>'ROU'</li>\n",
       "\t<li>'EGY'</li>\n",
       "\t<li>'AUT'</li>\n",
       "\t<li>'PHL'</li>\n",
       "\t<li>'RUS'</li>\n",
       "\t<li>'HRV'</li>\n",
       "\t<li>'CHL'</li>\n",
       "\t<li>''</li>\n",
       "\t<li>'SVK'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'BIH'\n",
       "\\item 'POL'\n",
       "\\item 'ESP'\n",
       "\\item 'JOR'\n",
       "\\item 'IND'\n",
       "\\item 'CAN'\n",
       "\\item 'SRB'\n",
       "\\item 'USA'\n",
       "\\item 'JPN'\n",
       "\\item 'TUR'\n",
       "\\item 'UKR'\n",
       "\\item 'GRC'\n",
       "\\item 'GBR'\n",
       "\\item 'PRT'\n",
       "\\item 'VEN'\n",
       "\\item 'PAK'\n",
       "\\item 'HKG'\n",
       "\\item 'ARG'\n",
       "\\item 'MEX'\n",
       "\\item 'MYS'\n",
       "\\item 'DEU'\n",
       "\\item 'BGD'\n",
       "\\item 'FIN'\n",
       "\\item 'ITA'\n",
       "\\item 'IDN'\n",
       "\\item 'BGR'\n",
       "\\item 'ROU'\n",
       "\\item 'EGY'\n",
       "\\item 'AUT'\n",
       "\\item 'PHL'\n",
       "\\item 'RUS'\n",
       "\\item 'HRV'\n",
       "\\item 'CHL'\n",
       "\\item ''\n",
       "\\item 'SVK'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'BIH'\n",
       "2. 'POL'\n",
       "3. 'ESP'\n",
       "4. 'JOR'\n",
       "5. 'IND'\n",
       "6. 'CAN'\n",
       "7. 'SRB'\n",
       "8. 'USA'\n",
       "9. 'JPN'\n",
       "10. 'TUR'\n",
       "11. 'UKR'\n",
       "12. 'GRC'\n",
       "13. 'GBR'\n",
       "14. 'PRT'\n",
       "15. 'VEN'\n",
       "16. 'PAK'\n",
       "17. 'HKG'\n",
       "18. 'ARG'\n",
       "19. 'MEX'\n",
       "20. 'MYS'\n",
       "21. 'DEU'\n",
       "22. 'BGD'\n",
       "23. 'FIN'\n",
       "24. 'ITA'\n",
       "25. 'IDN'\n",
       "26. 'BGR'\n",
       "27. 'ROU'\n",
       "28. 'EGY'\n",
       "29. 'AUT'\n",
       "30. 'PHL'\n",
       "31. 'RUS'\n",
       "32. 'HRV'\n",
       "33. 'CHL'\n",
       "34. ''\n",
       "35. 'SVK'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"BIH\" \"POL\" \"ESP\" \"JOR\" \"IND\" \"CAN\" \"SRB\" \"USA\" \"JPN\" \"TUR\" \"UKR\" \"GRC\"\n",
       "[13] \"GBR\" \"PRT\" \"VEN\" \"PAK\" \"HKG\" \"ARG\" \"MEX\" \"MYS\" \"DEU\" \"BGD\" \"FIN\" \"ITA\"\n",
       "[25] \"IDN\" \"BGR\" \"ROU\" \"EGY\" \"AUT\" \"PHL\" \"RUS\" \"HRV\" \"CHL\" \"\"    \"SVK\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "df.hit<- read.csv(\"/Users/sunevan/Dropbox/Spring 2017/Text As Data/HW2/CF_rate_trustworthiness.csv\",stringsAsFactors = F)\n",
    "unique(df.hit$X_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>X_unit_id</th><th scope=col>X_created_at</th><th scope=col>X_id</th><th scope=col>X_started_at</th><th scope=col>X_tainted</th><th scope=col>X_channel</th><th scope=col>X_trust</th><th scope=col>X_worker_id</th><th scope=col>X_country</th><th scope=col>X_region</th><th scope=col>X_city</th><th scope=col>X_ip</th><th scope=col>rating</th><th scope=col>image_name</th><th scope=col>url</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>182</th><td>726049343                                                              </td><td>5/26/2015 15:31:12                                                     </td><td>1643434072                                                             </td><td>5/26/2015 15:31:05                                                     </td><td>false                                                                  </td><td>clixsense                                                              </td><td>1                                                                      </td><td>31151345                                                               </td><td>                                                                       </td><td>                                                                       </td><td>                                                                       </td><td>185.79.230.246                                                         </td><td>7                                                                      </td><td>whitewoman8                                                            </td><td>https://raw.githubusercontent.com/kmunger/images/master/whitewoman8.jpg</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & X\\_unit\\_id & X\\_created\\_at & X\\_id & X\\_started\\_at & X\\_tainted & X\\_channel & X\\_trust & X\\_worker\\_id & X\\_country & X\\_region & X\\_city & X\\_ip & rating & image\\_name & url\\\\\n",
       "\\hline\n",
       "\t182 & 726049343                                                               & 5/26/2015 15:31:12                                                      & 1643434072                                                              & 5/26/2015 15:31:05                                                      & false                                                                   & clixsense                                                               & 1                                                                       & 31151345                                                                &                                                                         &                                                                         &                                                                         & 185.79.230.246                                                          & 7                                                                       & whitewoman8                                                             & https://raw.githubusercontent.com/kmunger/images/master/whitewoman8.jpg\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | X_unit_id | X_created_at | X_id | X_started_at | X_tainted | X_channel | X_trust | X_worker_id | X_country | X_region | X_city | X_ip | rating | image_name | url | \n",
       "|---|\n",
       "| 182 | 726049343                                                               | 5/26/2015 15:31:12                                                      | 1643434072                                                              | 5/26/2015 15:31:05                                                      | false                                                                   | clixsense                                                               | 1                                                                       | 31151345                                                                |                                                                         |                                                                         |                                                                         | 185.79.230.246                                                          | 7                                                                       | whitewoman8                                                             | https://raw.githubusercontent.com/kmunger/images/master/whitewoman8.jpg | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    X_unit_id X_created_at       X_id       X_started_at       X_tainted\n",
       "182 726049343 5/26/2015 15:31:12 1643434072 5/26/2015 15:31:05 false    \n",
       "    X_channel X_trust X_worker_id X_country X_region X_city X_ip          \n",
       "182 clixsense 1       31151345                              185.79.230.246\n",
       "    rating image_name \n",
       "182 7      whitewoman8\n",
       "    url                                                                    \n",
       "182 https://raw.githubusercontent.com/kmunger/images/master/whitewoman8.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hit[which(df.hit$X_country == ''),] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems that there is a data error that #182 row doesn't have country nationality. Remove this from the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X_unit_id</th><th scope=col>X_created_at</th><th scope=col>X_id</th><th scope=col>X_started_at</th><th scope=col>X_tainted</th><th scope=col>X_channel</th><th scope=col>X_trust</th><th scope=col>X_worker_id</th><th scope=col>X_country</th><th scope=col>X_region</th><th scope=col>X_city</th><th scope=col>X_ip</th><th scope=col>rating</th><th scope=col>image_name</th><th scope=col>url</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>726049306                                                            </td><td>5/26/2015 15:32:50                                                   </td><td>1643434598                                                           </td><td>5/26/2015 15:32:44                                                   </td><td>false                                                                </td><td>clixsense                                                            </td><td>1                                                                    </td><td>32145508                                                             </td><td>BIH                                                                  </td><td>01                                                                   </td><td>Sarajevo                                                             </td><td>185.13.242.248                                                       </td><td>4                                                                    </td><td>blackman1                                                            </td><td>https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg</td></tr>\n",
       "\t<tr><td>726049306                                                            </td><td>5/26/2015 15:32:54                                                   </td><td>1643434614                                                           </td><td>5/26/2015 15:32:46                                                   </td><td>false                                                                </td><td>neodev                                                               </td><td>1                                                                    </td><td>30448360                                                             </td><td>POL                                                                  </td><td>73                                                                   </td><td>Polska                                                               </td><td>31.61.136.172                                                        </td><td>1                                                                    </td><td>blackman1                                                            </td><td>https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " X\\_unit\\_id & X\\_created\\_at & X\\_id & X\\_started\\_at & X\\_tainted & X\\_channel & X\\_trust & X\\_worker\\_id & X\\_country & X\\_region & X\\_city & X\\_ip & rating & image\\_name & url\\\\\n",
       "\\hline\n",
       "\t 726049306                                                             & 5/26/2015 15:32:50                                                    & 1643434598                                                            & 5/26/2015 15:32:44                                                    & false                                                                 & clixsense                                                             & 1                                                                     & 32145508                                                              & BIH                                                                   & 01                                                                    & Sarajevo                                                              & 185.13.242.248                                                        & 4                                                                     & blackman1                                                             & https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg\\\\\n",
       "\t 726049306                                                             & 5/26/2015 15:32:54                                                    & 1643434614                                                            & 5/26/2015 15:32:46                                                    & false                                                                 & neodev                                                                & 1                                                                     & 30448360                                                              & POL                                                                   & 73                                                                    & Polska                                                                & 31.61.136.172                                                         & 1                                                                     & blackman1                                                             & https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "X_unit_id | X_created_at | X_id | X_started_at | X_tainted | X_channel | X_trust | X_worker_id | X_country | X_region | X_city | X_ip | rating | image_name | url | \n",
       "|---|---|\n",
       "| 726049306                                                             | 5/26/2015 15:32:50                                                    | 1643434598                                                            | 5/26/2015 15:32:44                                                    | false                                                                 | clixsense                                                             | 1                                                                     | 32145508                                                              | BIH                                                                   | 01                                                                    | Sarajevo                                                              | 185.13.242.248                                                        | 4                                                                     | blackman1                                                             | https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg | \n",
       "| 726049306                                                             | 5/26/2015 15:32:54                                                    | 1643434614                                                            | 5/26/2015 15:32:46                                                    | false                                                                 | neodev                                                                | 1                                                                     | 30448360                                                              | POL                                                                   | 73                                                                    | Polska                                                                | 31.61.136.172                                                         | 1                                                                     | blackman1                                                             | https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  X_unit_id X_created_at       X_id       X_started_at       X_tainted\n",
       "1 726049306 5/26/2015 15:32:50 1643434598 5/26/2015 15:32:44 false    \n",
       "2 726049306 5/26/2015 15:32:54 1643434614 5/26/2015 15:32:46 false    \n",
       "  X_channel X_trust X_worker_id X_country X_region X_city   X_ip          \n",
       "1 clixsense 1       32145508    BIH       01       Sarajevo 185.13.242.248\n",
       "2 neodev    1       30448360    POL       73       Polska   31.61.136.172 \n",
       "  rating image_name\n",
       "1 4      blackman1 \n",
       "2 1      blackman1 \n",
       "  url                                                                  \n",
       "1 https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg\n",
       "2 https://raw.githubusercontent.com/kmunger/images/master/blackman1.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hitnew <- df.hit[which(df.hit$X_country != ''),] \n",
    "head(df.hitnew,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nation <- unique(df.hitnew$X_country)\n",
    "\n",
    "p_value <- matrix(0,ncol = 1, nrow = length(nation))\n",
    "\n",
    "for (i in (1:length(nation))){\n",
    "    \n",
    "    x <- df.hit[which(df.hit$X_country == nation[i]),]$rating\n",
    "    y <- df.hit[which(df.hit$X_country != nation[i]),]$rating\n",
    "    if (length(x)==1){\n",
    "        p_value[i]<- 1 \n",
    "    }\n",
    "    else {\n",
    "        p_value[i] <- t.test(x,y,alternative = \"greater\")[\"p.value\"]  \n",
    "    } \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_value_df <- data.frame(as.matrix(nation),as.matrix(p_value))\n",
    "colnames(p_value_df) <- c(\"nationality\",\"p_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out signicant nationality \n",
    "p_value_nation<-p_value_df[which(p_value_df$p_value<=0.05),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute x_avg (the particular nationality) vs y_avg (all other nationality)\n",
    "X_avg <-  matrix(0,ncol = 1, nrow = nrow(p_value_nation))\n",
    "Y_avg <- matrix(0,ncol = 1, nrow = nrow(p_value_nation))\n",
    "\n",
    "for (i in (1:nrow(p_value_nation))){\n",
    "    \n",
    "    X_avg[i] <- mean(df.hit[which(df.hit$X_country == p_value_nation[i,1]),]$rating)\n",
    "    Y_avg[i] <- mean(df.hit[which(df.hit$X_country != p_value_nation[i,1]),]$rating)\n",
    "    \n",
    "}\n",
    "\n",
    "p_value_nation$X_avg <- X_avg\n",
    "p_value_nation$Y_avg <- Y_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>nationality</th><th scope=col>p_value</th><th scope=col>X_avg</th><th scope=col>Y_avg</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>8</th><td>USA       </td><td>0.03518437</td><td> 6.600000 </td><td>5.995349  </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>JPN         </td><td>0.0008219275</td><td> 8.166667   </td><td>5.948598    </td></tr>\n",
       "\t<tr><th scope=row>13</th><td>GBR        </td><td>0.007040027</td><td> 7.714286  </td><td>5.953052   </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>HKG       </td><td>0.02397056</td><td> 7.000000 </td><td>5.971698  </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>DEU       </td><td>0.01374244</td><td> 7.000000 </td><td>5.986047  </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>BGR       </td><td>0.01862525</td><td> 8.600000 </td><td>5.948837  </td></tr>\n",
       "\t<tr><th scope=row>30</th><td>PHL       </td><td>0.04535236</td><td> 9.000000 </td><td>5.967742  </td></tr>\n",
       "\t<tr><th scope=row>33</th><td>CHL        </td><td>1.20607e-73</td><td>10.000000  </td><td>5.972477   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & nationality & p\\_value & X\\_avg & Y\\_avg\\\\\n",
       "\\hline\n",
       "\t8 & USA        & 0.03518437 &  6.600000  & 5.995349  \\\\\n",
       "\t9 & JPN          & 0.0008219275 &  8.166667    & 5.948598    \\\\\n",
       "\t13 & GBR         & 0.007040027 &  7.714286   & 5.953052   \\\\\n",
       "\t17 & HKG        & 0.02397056 &  7.000000  & 5.971698  \\\\\n",
       "\t21 & DEU        & 0.01374244 &  7.000000  & 5.986047  \\\\\n",
       "\t26 & BGR        & 0.01862525 &  8.600000  & 5.948837  \\\\\n",
       "\t30 & PHL        & 0.04535236 &  9.000000  & 5.967742  \\\\\n",
       "\t33 & CHL         & 1.20607e-73 & 10.000000   & 5.972477   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | nationality | p_value | X_avg | Y_avg | \n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 8 | USA        | 0.03518437 |  6.600000  | 5.995349   | \n",
       "| 9 | JPN          | 0.0008219275 |  8.166667    | 5.948598     | \n",
       "| 13 | GBR         | 0.007040027 |  7.714286   | 5.953052    | \n",
       "| 17 | HKG        | 0.02397056 |  7.000000  | 5.971698   | \n",
       "| 21 | DEU        | 0.01374244 |  7.000000  | 5.986047   | \n",
       "| 26 | BGR        | 0.01862525 |  8.600000  | 5.948837   | \n",
       "| 30 | PHL        | 0.04535236 |  9.000000  | 5.967742   | \n",
       "| 33 | CHL         | 1.20607e-73 | 10.000000   | 5.972477    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   nationality p_value      X_avg     Y_avg   \n",
       "8  USA         0.03518437    6.600000 5.995349\n",
       "9  JPN         0.0008219275  8.166667 5.948598\n",
       "13 GBR         0.007040027   7.714286 5.953052\n",
       "17 HKG         0.02397056    7.000000 5.971698\n",
       "21 DEU         0.01374244    7.000000 5.986047\n",
       "26 BGR         0.01862525    8.600000 5.948837\n",
       "30 PHL         0.04535236    9.000000 5.967742\n",
       "33 CHL         1.20607e-73  10.000000 5.972477"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_value_nation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# remove number from the string \n",
    "df.hit$demographic <-gsub('[0-9]+', '', df.hit$image_name)\n",
    "\n",
    "# process data for race and gender \n",
    "Gender <- matrix(0,ncol = 1, nrow = nrow(df.hit))\n",
    "for (i in (1:nrow(df.hit))){\n",
    "    if (df.hit$demographic[i] == \"whitewoman\") {\n",
    "        Gender[i] <- \"w\"        \n",
    "    }\n",
    "    else {\n",
    "        Gender[i] <- \"m\"\n",
    "        \n",
    "    }\n",
    "              \n",
    "    }\n",
    "\n",
    "df.hit$Gender <- Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demographic.aov <- aov(df.hit$rating ~ df.hit$demographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Df Sum Sq Mean Sq F value Pr(>F)  \n",
       "df.hit$demographic   2   34.6  17.284   3.776 0.0244 *\n",
       "Residuals          217  993.4   4.578                 \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(demographic.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0244, so it is significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  woman and man\n",
       "t = 1.7449, df = 137.06, p-value = 0.08324\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.07363011  1.17891746\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 6.373333  5.820690 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "man <- df.hit[which(df.hit$Gender == 'm'),]$rating\n",
    "woman <- df.hit[which(df.hit$Gender != 'm'),]$rating\n",
    "t.test(woman,man)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'clixsense'</li>\n",
       "\t<li>'neodev'</li>\n",
       "\t<li>'elite'</li>\n",
       "\t<li>'tremorgames'</li>\n",
       "\t<li>'points4rewards'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'clixsense'\n",
       "\\item 'neodev'\n",
       "\\item 'elite'\n",
       "\\item 'tremorgames'\n",
       "\\item 'points4rewards'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'clixsense'\n",
       "2. 'neodev'\n",
       "3. 'elite'\n",
       "4. 'tremorgames'\n",
       "5. 'points4rewards'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"clixsense\"      \"neodev\"         \"elite\"          \"tremorgames\"   \n",
       "[5] \"points4rewards\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(df.hit$X_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) I will ask if different channel is related to the ratings. It seems that someone is doing the test for rewards. Maybe this group of people will spend much less time to really focus on the ratings and give random answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.aov <- aov(df.hit$rating ~ df.hit$image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   Df Sum Sq Mean Sq F value  Pr(>F)   \n",
       "df.hit$image_name  43  310.4   7.218    1.77 0.00541 **\n",
       "Residuals         176  717.6   4.077                   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(image.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Also, the quality of the image self. It is clear that it is significant that different images has clearly different average rating. I will ask them to filter images that have clearly higher or lower average rating than others. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
